## 激活函数

- NLP-机器学习笔试面试题解析 [Github链接](https://github.com/WerterHong/Machine-Learning-Algorithm-NLP/)
- **激活函数** (若公式显示错误，请点击此链接) [有道云笔记](http://note.youdao.com/noteshare?id=61e22de3ed9ed9bb6d733fedf7245dbc&sub=81109D23317D485CA1FC1511699E9B6E)

### 1. Sigmoid函数

`Sigmoid`函数是神经网络中常用的激活函数之一，`logistic`函数也就是经常说的`sigmoid`函数，它的几何形状也就是一条`sigmoid`曲线（S型曲线），其定义为：

```math
\sigma ( x ) = \frac { 1 } { 1 + e ^ { - x } }
```

该函数的定义域为`(-∞,+∞)`，值域`(0,1)`，其函数曲线如下：

<p align="center">
    <img src="https://note.youdao.com/yws/public/resource/61e22de3ed9ed9bb6d733fedf7245dbc/074B839FF9F44FECAC4BC3080D467083?ynotemdtimestamp=1565326757474" width=500 />
    <br/>
    <strong>Fig</strong>. Sigmoid函数曲线
</p>

`Sigmoid`函数具有如下的特性：当`x`趋近于负无穷时，`y`趋近于`0`；当`x`趋近于正无穷时，`y`趋近于`1`；当`x= 0`时，`y=0.5`。

**优点**：

1. `Sigmoid`函数的输出映射在`(0,1)`之间，单调连续，输出范围有限，优化稳定，可以用作输出层。
2. 求导容易。

> `sigmoid`**函数**的导函数具有以下形式：

```math
\sigma ^ { \prime } ( x ) = \sigma ( x ) [ 1 - \sigma ( x ) ]
```

> 函数`log σ(x)`和`log (1-σ(x))`的导函数分别为：

```math
[ \log \sigma ( x ) ] ^ { \prime } = 1 - \sigma ( x ) , \quad [ \log ( 1 - \sigma ( x ) ) ] ^ { \prime } = - \sigma ( x )
```

**缺点**：

1. 由于其软饱和性，容易产生梯度消失，导致训练出现问题。
2. 其输出并不是以0为中心的。
