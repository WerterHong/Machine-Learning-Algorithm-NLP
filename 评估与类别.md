## 评估与类别

- NLP-机器学习笔试面试题解析 [Github链接](https://github.com/WerterHong/Machine-Learning-Algorithm-NLP/)
- **评估与类别** (若公式显示错误，请点击此链接) [有道云笔记](http://note.youdao.com/noteshare?id=eb84a293592d2639dab29e205fdd3895&sub=B21FA6BC931C4836A9D3EA0E6DABAAF6)

### 1. F1

混淆矩阵

- True Positive(真正例, TP)：将正类预测为正类数.
- False Negative(假负例, FN)：将正类预测为负类数 → 漏报 (Type II error).
- False Positive(假正例, FP)：将负类预测为正类数 → 误报 (Type I error).
- True Negative(真反例, TN)：将负类预测为负类数.

<p align="center">
<table>
  <tr>
    <th rowspan="2"><br>真实情况</th>
    <th colspan="2">预测结果</th>
  </tr>
  <tr>
    <td>正例 Positive</td>
    <td>反例 Negative</td>
  </tr>
  <tr>
    <td>正例 True</td>
    <td>True Positive (TP)</td>
    <td>True Negative (TN)</td>
  </tr>
  <tr>
    <td>反例 False</td>
    <td>False Positive (FP)</td>
    <td>False Negative (FN)</td>
  </tr>
</table>
</p>

**精确率**(precision)定义为：

```math
Precision=\frac{TP}{TP+FP}
```

需要注意的是精确率(precision)和准确率(accuracy)是不一样的，

```math
Accuracy=\frac{TP}{TP+TN+FP+FN}
```
其中`$TP+TN+FP+FN=样本总例$`。

==在正负样本不平衡的情况下，准确率这个评价指标有很大的缺陷==。比如在互联网广告里面，点击的数量是很少的，一般只有千分之几，如果用acc，即使全部预测成负类（不点击）acc 也有 99% 以上，没有意义。

**召回率**(recall, sensitivity, true positive rate)定义为：

```math
Recall=\frac{TP}{TP+FN}
```

精准率和召回率示意图如下：

<p align="center">
    <img src="https://note.youdao.com/yws/public/resource/eb84a293592d2639dab29e205fdd3895/89AF446BE22F4B7ABB2C4F49F5B94E89?ynotemdtimestamp=1565228866471" />
    <br/>
    <strong>Fig</strong>. 精准率和召回率示意图
</p>

此外，还有`F1`值，是==精确率和召回率的调和均值==，

```math
\frac{2}{F_1}=\frac{1}{Precision}+\frac{1}{Recall}

F_1=\frac{2*Precision*Recall}{Precision+Recall}=\frac{2*TP}{2*TP+FP+FN}=\frac{2*TP}{样本总例+TP-TN}
```

精确率和准确率都高的情况下，`F1`值也会高。

**ROC曲线**

ROC曲线的横轴是"真正例率"(`True Positive Rate, TPR`)，纵轴是"假正例率"(`False Positive Rate, FPR`)，两者分别定义为：

```math
TPR=\frac{TP}{TP+FN}, \quad FPR=\frac{FP}{TN+FP}
```

### 2. 困惑度`PPL(perplexity)`

> 在信息论中，`perplexity`(困惑度)用来度量一个概率分布或概率模型预测样本的好坏程度。它也可以用来比较两个概率分布或概率模型（比较两者在预测样本上的优劣）。==低困惑度的概率分布模型或概率模型能更好地预测样本==。
>
>  定义==离散概率分布的困惑度==如下：

```math
2^{H(p)}=2^{-\sum_{x} p(x) \log _{2} p(x)}
```
> 其中`H(p)`是概率分布`p`的熵。

> 用一个概率模型`q`去估计真实概率分布`p`，则可以定义==概率模型的困惑度==如下：

```math
b^{-\frac{1}{N} \sum_{i=1}^{N} 1^{\log _{b} q\left(x_{i}\right)}}
```
> 其中，指数部分是交叉熵`H(p,q)`。

**困惑度**`PPL`用在自然语言处理领域（NLP）中，衡量语言模型好坏的指标(==测试集==)。它主要==是根据每个词来估计一句话出现的概率，并用句子长度作`normalize`==，公式为

```math
\begin{aligned} P P(S) &=P\left(w_{1} w_{2} \ldots w_{N}\right)^{-\frac{1}{N}} \\ &=\sqrt[N]{\frac{1}{p\left(w_{1} w_{2} \ldots w_{N}\right)}} \\ &=\sqrt[N]{\prod_{i=1}^{N} \frac{N}{p\left(w_{i} | w_{1} w_{2} \ldots w_{i-1}\right)}} \end{aligned}
```
其中`S`代表`sentence`，`N`是句子长度，`$p(w_i)$`是第`i`个词的概率。第一个词就是`$p(w_1|w_0)$`，而`$w_0$`是`START`，表示句子的起始，是个占位符。

==困惑度`PPL`越小==，`$p(w_i)$`则越大，我们期望的`sentence`==出现的概率就越高==。

- 对于整个测试集，对所有句子的`perplexity`，求==几何平均==，得到整体的结果(`$N^{\prime}$`表示测试集句子长度之和，即`$N^{\prime}=\sum (N_k + 1)$`)

```math
Perplexity_{avg}=P(S)^{-\frac{1}{{N}^{\prime}}}=2^{-\frac{1}{N^{\prime}} \cdot \log P(S)}=2^{-\frac{\sum \log P\left(s_{k}\right)}{\sum\left(N_{k}+1\right)}}
```
> (1) 困惑度中的指数表达形式，其中`$-\frac{1}{N^{\prime}} \cdot \log P(S)$`可以理解为（对词平均的）==交叉熵==(`cross-entropy`)，也就是`$H(q,p)=-\sum q(w)\log p(w)$`。
>
> (2) `q(w)`是==经验分布==，即`$\frac{n}{N^{\prime}}$`，`n=Count(w)`，`−log p(w)`表示其信息量（编码长度）
>
> (3) `perplexity`就是在某种编码方式（语言模型）下评估==测试集的平均编码长度==，也就是交叉熵的含义
>
> (4) `LM`拟合得越好，即==模型越贴近真实分布`q`，`perplexity`/交叉熵越小，`KL`散度越小，越接近真实分布的熵==

### 3. `Mean Average Precision, MAP`

单个主题的平均准确率是每篇相关文档检索出后的准确率的平均值。主集合的平均准确率(`MAP`)是==每个主题的平均准确率的平均值==。`MAP`是反映系统在全部相关文档上性能的==单值指标==。系统检索出来的相关文档越靠前(`rank`越高)，MAP就可能越高。如果系统没有返回相关文档，则准确率默认为`0`。

`mAP`是为解决`P，R，F-measure`的单点值局限性的。为了得到一个能够==反映全局性能的指标==，可以看考察下图，其中两条曲线(方块点与圆点)分布对应了两个检索系统的准确率-召回率曲线：

<p align="center">
    <img src="https://note.youdao.com/yws/public/resource/eb84a293592d2639dab29e205fdd3895/890C5A268FFB41BFB6090A6643DF376C?ynotemdtimestamp=1565232292472" />
    <br/>
    <strong>Fig</strong>. 精准率和召回曲线
</p>

如果一个系统的性能较好，其曲线应当尽可能的==向上突出==。平均准确率`AP`其定义如下:

```math
AP=\frac{\sum^{n_i}_{j=1}P(j) \cdot y_{i,j}}{\sum^{n_i}_{j=1}y_{i,j}}
```
其中，`$y_{i,j}$`排序中第`j`个元素对于查询`i`是否是相关的；相关为`1`，不相关为`0`。

```math
P(j)=\frac{\sum_{k:π_i(k) \leq π_i(j)}y_{j,k}}{π_i(j)}
```
其中，`$π_i(j)$`为`j`的排序位置。

**例**：

| rank_num | 是否相关 |
|:--------:|:--------:|
|     1    |     1    |
|     2    |     0    |
|     3    |     1    |
|     4    |     0    |
|     5    |     1    |
|     6    |     0    |

根据`AP`计算公式：

```math
AP=(1 \times 1 + \frac{1}{2} \times 0 + \frac{2}{3} \times 1 + \frac{2}{4} \times 0 + \frac{3}{5} \times 1 + \frac{3}{6} \times 0) / 3 = \cdots
```
> `MAP`就是对所有`query`的`AP`求==平均==。

### 4. `Mean Reciprocal Rank, MRR`

`MRR`是把标准答案在被评价系统给出结果中的==排序取倒数==作为它的准确度，再对所有的问题取平均。

```math
\mathrm{MRR}=\frac{1}{|Q|} \sum_{i=1}^{|Q|} \frac{1}{\mathrm{rank}_{i}}
```
其中`|Q|`是查询个数，`$rank_i$`是第`i`个查询，第一个相关的结果所在的排列位置。

### 5. 熵/信息熵/`KL`散度

详情见[信息熵](http://note.youdao.com/noteshare?id=3e095525a3d4c58a43349b1f346b5a8f&sub=48B3B98D1C4E4477A34CDEBEC2992866)。
