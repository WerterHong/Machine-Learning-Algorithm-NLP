## 朴素贝叶斯

- NLP-机器学习笔试面试题解析 [Github链接](https://github.com/WerterHong/Machine-Learning-Algorithm-NLP/)
- **朴素贝叶斯** (若公式显示错误，请点击此链接) [有道云笔记](http://note.youdao.com/noteshare?id=0693c471d86002cc0bae2403a96e6632&sub=B89A3590BCC74A21BAA0183AE3418CDD)

朴素贝叶斯（Naïve Bayes）法是基于**贝叶斯定理**与**特征条件独立假设**的分类方法。
> 朴素：特征条件独立
>
> 贝叶斯：基于贝叶斯定理

贝叶斯定理：

```math
p(y | x)=\frac{p(x | y) p(y)}{p(x)}
```

朴素贝叶斯法实际上学习到生成数据的机制，因为其学习的是一个**联合概率分布**，所以属于**生成模型**。

### 1. 朴素贝叶斯法

假设输入空间`$\mathcal{X} \subseteq R^{n}$`为`n`维向量的集合，输出空间为类标记的集合`$\mathcal{Y} \subseteq\left\{c_{1}, c_{2}, \cdots, c_{K}\right\}$`.输入特征向量`$x \in \mathcal{X}$`,输出类标记`$y \in \mathcal{Y}$`.`X`是定义在输出空间`$\mathcal{X}$`上的随机变量，`Y`是定义在输出空间`$\mathcal{Y}$`上的随机变量.`P(X,Y)`是`X`和`Y`上的联合概率分布。训练数据集为

```math
T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \ldots,\left(x_{N}, y_{N}\right)\right\}
```

由`P(X,Y)`独立同分布产生。

朴素贝叶斯法通过训练数据集学习联合概率分布`P(X,Y)`。
- 学习先验概率分布以及条件概率分布,得到联合概率分布`P(X,Y)`
> 先验概率分布

```math
P\left(Y=c_{k}\right), k=1,2,3, \cdots, K
```

> 条件概率分布

```math
P\left(X=x | Y=c_{k}\right)=P\left(X^{(1)}=x^{1}, \cdots, X^{(n)}=x^{(n)} | Y=c_{k}\right), k=1,2, \cdots, K
```

> - 条件概率分布有**指数级数量的参数**，其估计实际是不可行的.

朴素贝叶斯法对条件概率分布做了**条件独立性假设**。假设**用于分类的特征在类稳定的条件下都是条件独立的**，模型包含的条件概率的数量大大减少，学习与预测大为简化，但是会损失准确率。条件独立性假设是[式(1.1)]：

```math
P\left(X=x | Y=c_{k}\right)=P\left(X^{(1)}=x^{(1)}, \cdots, X^{(n)} | Y=c_{k}\right)=\prod_{j=1}^{n} P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)
```

朴素贝叶斯方法在分类时，对给定的输入`x`, 通过学习到的模型计算后验概率分`$P(Y=c_k|X=x)$` 将后验概率最大的类作为`x`类的输出，后验概率计算可以依据贝叶斯定理进行[式(1.2)]：

```math
P\left(Y=c_{k} | X=x\right)=\frac{P\left(X=x | Y=c_{k}\right) P\left(Y=c_{k}\right)}{\sum_{k} P\left(X=x Y=c_{k}\right) P\left(Y=c_{k}\right)}
```

将式(1.1)代入式(1.2)式，得到：

```math
P\left(Y=c_{k} | X=x\right)=\frac{P\left(Y=c_{k}\right) \Pi_{j} P\left(X^{(j)}=x^{(j)} Y=c_{k}\right)}{\sum_{k} P\left(Y=c_{k}\right) \Pi_{j} P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)}, k=1,2, \cdots, K
```

式(1.3)是朴素贝叶斯分类的基本公式。朴素贝叶斯分类器可表示为：

```math
y=f(x)=\arg \max _{c k} \frac{P\left(Y=c_{k}\right) \Pi_{j} P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)}{\sum_{k} P\left(Y=c_{k}\right) \prod_{j} P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)}
```

简化得到最终的**贝叶斯分类器的决策函数**为：

```math
y=\arg \max _{c k} P\left(Y=c_{k}\right) \prod_{j} P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)
```

#### 后验概率最大化

详情见《统计学习方法》4.1.2  P48 以及《机器学习》

### 2. 参数估计(极大似然函数)

[详情见参数估计](http://note.youdao.com/noteshare?id=876755ce4fa84929b7dc7c3dc51581c4&sub=4E33F7496EEF4BD98A029A09498CFA5C)。
