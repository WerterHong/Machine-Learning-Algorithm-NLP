## 评估与类别

- NLP-机器学习笔试面试题解析 [Github链接](https://github.com/WerterHong/Machine-Learning-Algorithm-NLP/)
- **评估与类别** (若公式显示错误，请点击此链接) [有道云笔记](http://note.youdao.com/noteshare?id=eb84a293592d2639dab29e205fdd3895&sub=B21FA6BC931C4836A9D3EA0E6DABAAF6)

### 1. F1

混淆矩阵

- True Positive(真正例, TP)：将正类预测为正类数.
- False Negative(假负例, FN)：将正类预测为负类数 → 漏报 (Type II error).
- False Positive(假正例, FP)：将负类预测为正类数 → 误报 (Type I error).
- True Negative(真反例, TN)：将负类预测为负类数.

<p align="center">
<table>
  <tr>
    <th rowspan="2"><br>真实情况</th>
    <th colspan="2">预测结果</th>
  </tr>
  <tr>
    <td>正例 Positive</td>
    <td>反例 Negative</td>
  </tr>
  <tr>
    <td>正例 True</td>
    <td>True Positive (TP)</td>
    <td>True Negative (TN)</td>
  </tr>
  <tr>
    <td>反例 False</td>
    <td>False Positive (FP)</td>
    <td>False Negative (FN)</td>
  </tr>
</table>
</p>

**精确率**(precision)定义为：

```math
Precision=\frac{TP}{TP+FP}
```

需要注意的是精确率(precision)和准确率(accuracy)是不一样的，

```math
Accuracy=\frac{TP}{TP+TN+FP+FN}
```
其中`$TP+TN+FP+FN=样本总例$`。

==在正负样本不平衡的情况下，准确率这个评价指标有很大的缺陷==。比如在互联网广告里面，点击的数量是很少的，一般只有千分之几，如果用acc，即使全部预测成负类（不点击）acc 也有 99% 以上，没有意义。

**召回率**(recall, sensitivity, true positive rate)定义为：

```math
Recall=\frac{TP}{TP+FN}
```

此外，还有`F1`值，是==精确率和召回率的调和均值==，

```math
\frac{2}{F_1}=\frac{1}{Precision}+\frac{1}{Recall}

F_1=\frac{2*Precision*Recall}{Precision+Recall}=\frac{2*TP}{2*TP+FP+FN}=\frac{2*TP}{样本总例+TP-TN}
```

精确率和准确率都高的情况下，`F1`值也会高。

### 2. 困惑度`PPL(perplexity)`

> 在信息论中，`perplexity`(困惑度)用来度量一个概率分布或概率模型预测样本的好坏程度。它也可以用来比较两个概率分布或概率模型（比较两者在预测样本上的优劣）。==低困惑度的概率分布模型或概率模型能更好地预测样本==。
>
>  定义==离散概率分布的困惑度==如下：

```math
2^{H(p)}=2^{-\sum_{x} p(x) \log _{2} p(x)}
```
> 其中`H(p)`是概率分布`p`的熵。

> 用一个概率模型`q`去估计真实概率分布`p`，则可以定义==概率模型的困惑度==如下：

```math
b^{-\frac{1}{N} \sum_{i=1}^{N} 1^{\log _{b} q\left(x_{i}\right)}}
```
> 其中，指数部分是交叉熵`H(p,q)`。

**困惑度**`PPL`用在自然语言处理领域（NLP）中，衡量语言模型好坏的指标(==测试集==)。它主要==是根据每个词来估计一句话出现的概率，并用句子长度作`normalize`==，公式为

```math
\begin{aligned} P P(S) &=P\left(w_{1} w_{2} \ldots w_{N}\right)^{-\frac{1}{N}} \\ &=\sqrt[N]{\frac{1}{p\left(w_{1} w_{2} \ldots w_{N}\right)}} \\ &=\sqrt[N]{\prod_{i=1}^{N} \frac{N}{p\left(w_{i} | w_{1} w_{2} \ldots w_{i-1}\right)}} \end{aligned}
```
其中`S`代表`sentence`，`N`是句子长度，`$p(w_i)$`是第`i`个词的概率。第一个词就是`$p(w_1|w_0)$`，而`$w_0$`是`START`，表示句子的起始，是个占位符。

==困惑度`PPL`越小==，`$p(w_i)$`则越大，我们期望的`sentence`==出现的概率就越高==。

- 对于整个测试集，对所有句子的`perplexity`，求==几何平均==，得到整体的结果(`$N^{\prime}$`表示测试集句子长度之和，即`$N^{\prime}=\sum (N_k + 1)$`)

```math
Perplexity_{avg}=P(S)^{-\frac{1}{{N}^{\prime}}}=2^{-\frac{1}{N^{\prime}} \cdot \log P(S)}=2^{-\frac{\sum \log P\left(s_{k}\right)}{\sum\left(N_{k}+1\right)}}
```
> (1) 困惑度中的指数表达形式，其中`$-\frac{1}{N^{\prime}} \cdot \log P(S)$`可以理解为（对词平均的）==交叉熵==(`cross-entropy`)，也就是`$H(q,p)=-\sum q(w)\log p(w)$`。
>
> (2) `q(w)`是==经验分布==，即`$\frac{n}{N^{\prime}}$`，`n=Count(w)`，`−log p(w)`表示其信息量（编码长度）
>
> (3) `perplexity`就是在某种编码方式（语言模型）下评估==测试集的平均编码长度==，也就是交叉熵的含义
>
> (4) `LM`拟合得越好，即==模型越贴近真实分布`q`，`perplexity`/交叉熵越小，`KL`散度越小，越接近真实分布的熵==

### 3. `Mean Average Precision, MAP`

### 4. `Mean Reciprocal Rank, MRR`

### 5. 熵/信息熵/`KL`散度

详情见[信息熵](http://note.youdao.com/noteshare?id=3e095525a3d4c58a43349b1f346b5a8f&sub=48B3B98D1C4E4477A34CDEBEC2992866)。
